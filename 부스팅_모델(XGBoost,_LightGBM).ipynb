{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "부스팅 모델(XGBoost, LightGBM)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KIMCAT33/Machine-Learning/blob/master/%EB%B6%80%EC%8A%A4%ED%8C%85_%EB%AA%A8%EB%8D%B8(XGBoost%2C_LightGBM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmv54MHi_wZ8",
        "colab_type": "text"
      },
      "source": [
        "<H3>Bagging(앙상블 방법) - 주어진 데이터에 대해서 여러 개의 랜덤 복원 샘플링을 하고 각 샘플의 모델링을 통해 나온 값을 평균하거나 다중 투표하는 방식으로 예측 모형의 분산을 줄여 줌으로써 예측력을 향상 시키는 방법입니다.\n",
        "\n",
        "일반적으로 과대적합된 모형, 분산이 큰 모형에 사용하는 것이 적합합니다.\n",
        "\n",
        "RandomForest 같은 모델입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Pjps37-o7h",
        "colab_type": "text"
      },
      "source": [
        "<H3>Gradient Boosting (앙상블 방법) - 회귀(Regression) 분석 or 분류 (Classificaiton)  \n",
        "\n",
        "테이블 형태의 데이터에 대해서 엄청난 성능을 나타낸다.\n",
        "\n",
        "LightGBM, CatBoost, XGBoost(extreme gradient boosting)이 Gradient Boosting 모델이다.\n",
        "</H3>\n",
        "\n",
        "\n",
        "<center>< 테이블 형태의 데이터>\n",
        "\n",
        "![alt text](https://d13ot9o61jdzpp.cloudfront.net/images/tabular_data_1_the_perfect_format.png) </center>\n",
        "\n",
        "부스팅 모델은 잘못 분류된 개체들에 집중하여 새로운 분류 규칙을 만드는 단계를 반복하는 방법입니다. 즉, 처음 데이터의 객체들은 동일한 가중치에서 시장하지만, 모델링을 통해 오분류된 개체들에게는 높은 가중치를 부여하고, 정분류된 객체들에게 낮은 가중치를 부여하여 오분류된 객체들이 더 잘 분류되도록 만드는 방법입니다.\n",
        "\n",
        "![alt text](https://i.imgur.com/MvCGENh.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWwRSIyP-8e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 입력\n",
        "\"\"\"\n",
        " X = pd.read_csv('train.csv', index_col='Id')\n",
        " x_test_full = pd.read_csv('test.csv', index_col='Id')\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Ebo59AyNs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 결측치 제거 및 레이블 분리 \n",
        "\"\"\"\n",
        " X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
        " y = X.SalePrice\n",
        " X.drop(['SalePrice'], axis=1, inplace=True)\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfN9-C9yc2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련 데이터와 검증 데이터 분리 \n",
        "\n",
        "# X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ2lY00cyomd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리 개수가 적은 columns만 뽑아보기\n",
        "\n",
        "# low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W_tIHdIyzOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 숫자형 column만 뽑아보기\n",
        "\n",
        "# numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f27WKiaHy_7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 선택된 columns으로 새로운 훈련, 검증, 테스트 데이터 셋 만들기\n",
        "\"\"\"\n",
        "my_cols = low_cardinality_cols + numeric_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()\n",
        "X_test = x_test_full[my_cols].copy() \n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjD6ESy4Omaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리 타입(\"object\") 을 숫자형(One-hot encoding)로 변환\n",
        "\"\"\" \n",
        "def Categorical_to_nummeric(X_train, X_valid, X_test):\n",
        "  X_train = pd.get_dummies(X_train)\n",
        "  X_valid = pd.get_dummies(X_valid)\n",
        "  X_test = pd.get_dummies(X_test)\n",
        "\n",
        "  X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
        "  X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
        "\n",
        "  return X_train, X_valid, X_test\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 랜덤 포레스트 모델 훈련시키는 함수\n",
        "\"\"\"\n",
        "def RandomForess_train(train_X, train_y):\n",
        "  from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "  # Define the model. Set random_state to 1\n",
        "  rf_model = RandomForestRegressor(random_state=0)\n",
        "\n",
        "  # fit your model\n",
        "  model = rf_model.fit(train_X, train_y)\n",
        "  return model\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# XGBboost 모델 훈련시키는 함수\n",
        "\"\"\"\n",
        "def XGBboost_train(X_train, y_train, X_valid, y_valid):\n",
        "  from xgboost import XGBRegressor\n",
        "  model= XGBRegressor(n_estimator=1000, learning_rate=0.05, n_jobs=-1, random_state=0)\n",
        "  model.fit(X_train, y_train,\n",
        "              eval_set=[(X_valid, y_valid)],\n",
        "              early_stopping_rounds=5,\n",
        "              verbose=False)\n",
        "  return model\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 모델 성능 평가\n",
        "\"\"\"\n",
        "def predict_evaluate(model, X_test, y_test):\n",
        "  from sklearn.metrics import mean_absolute_error\n",
        "  prediction = model.predict(X_test)\n",
        "  mae = mean_absolute_error(prediction, y_test)\n",
        "  return mae\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3svgkDGLKV",
        "colab_type": "code",
        "outputId": "8863ac70-26c4-4969-f43c-bf3d5a5b3df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        " # 카테고리 데이터를 숫자형으로 인덱싱합니다. (One-Hot Encoding 방법)\n",
        "\n",
        "X_train, X_valid, X_test = Categorical_to_nummeric(X_train, X_valid, X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[06:26:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "\n",
            "============== XGBboost model predict score============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17748.012655179795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ4u7GU-0RMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XGBboost_model = XGBboost_train(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "print(\"\\n\\n============== XGBboost model predict score============\")\n",
        "predict_evaluate(XGBboost_model, X_valid, y_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Y5LTCQN8zx",
        "colab_type": "code",
        "outputId": "4cc4d26b-3621-43f4-b311-4ddf797745ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# XGBboost, LightGBM 과 Random Forest 성능 비교\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "# 데이터 불러오기\n",
        "\"\"\"\n",
        "home_data = pd.read_csv(\"new_train.csv\")\n",
        "y = home_data.SalePrice\n",
        "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
        "X = home_data[features]\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[06:46:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "\n",
            "============== Random Forest Model predict score============\n",
            "Validation MAE for Random Forest Model: 25474.17279843444\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============== XGBboost model predict score============\n",
            "Validation MAE for XGBboost Model: 24023.17861729452\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============== LightGBM model predict score============\n",
            "Validation MAE for LightGBM model: 23528.651089825627\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNsriXu0qhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#랜덤 포레스트 모델 학습\n",
        "\"\"\"\n",
        "rf_model = RandomForestRegressor(random_state=0)\n",
        "model_rf = rf_model.fit(train_X, train_y)\n",
        "prediction_rf = model_rf.predict(val_X)\n",
        "mae_rf = mean_absolute_error(prediction_rf, val_y)\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AszA83hW0ri0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#XGB Boost 모델 학습\n",
        "\"\"\"\n",
        "model_xgb= XGBRegressor(n_estimator=1000, learning_rate=0.05, n_jobs=-1, random_state=0)\n",
        "model_xgb.fit(train_X, train_y,\n",
        "            eval_set=[(val_X, val_y)],\n",
        "            early_stopping_rounds=5,\n",
        "            verbose=False)\n",
        "prediction_xgb = model_xgb.predict(val_X)\n",
        "mae_XGB = mean_absolute_error(prediction_xgb, val_y)\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj-qjfCFXMwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Light GBM 모델 학습\n",
        "\n",
        "params = {'learning_rate': 0.01, \n",
        "          'max_depth': 16, \n",
        "          'boosting': 'gbdt', \n",
        "          'objective': 'regression', \n",
        "          'metric': 'auc',\n",
        "          'is_training_metric': True,\n",
        "          'num_leaves': 144,\n",
        "          'feature_fraction': 0.9,\n",
        "          'bagging_fraction': 0.7,\n",
        "          'bagging_freq': 5,\n",
        "          'seed':0}\n",
        "\n",
        "          \n",
        "\"\"\"\n",
        "train_ds = lgb.Dataset(train_X, label = train_y)\n",
        "val_ds = lgb.Dataset(val_X, label = val_y)\n",
        "model_GBM = lgb.train(params,train_ds, 1000, verbose_eval=10)\n",
        "prediction_light_GBM = model_GBM.predict(val_X)\n",
        "mae_GBM = mean_absolute_error(prediction_light_GBM, val_y)\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIoQzodVsMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 성능 비교\n",
        "\n",
        "print(\"\\n\\n============== Random Forest Model predict score============\")\n",
        "print(\"Validation MAE for Random Forest Model: {}\\n\\n\".format(mae_rf))\n",
        "\n",
        "print(\"\\n\\n============== XGBboost model predict score============\")\n",
        "print(\"Validation MAE for XGBboost Model: {}\\n\\n\".format(mae_XGB))\n",
        "\n",
        "print(\"\\n\\n============== LightGBM model predict score============\")\n",
        "print(\"Validation MAE for LightGBM model: {}\\n\\n\".format(mae_GBM))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}