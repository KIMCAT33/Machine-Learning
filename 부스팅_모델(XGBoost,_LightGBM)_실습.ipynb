{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "부스팅 모델(XGBoost, LightGBM) - 실습",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KIMCAT33/Machine-Learning/blob/master/%EB%B6%80%EC%8A%A4%ED%8C%85_%EB%AA%A8%EB%8D%B8(XGBoost%2C_LightGBM)_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmv54MHi_wZ8",
        "colab_type": "text"
      },
      "source": [
        "<H3>Bagging(앙상블 방법) - 주어진 데이터에 대해서 여러 개의 랜덤 복원 샘플링을 하고 각 샘플의 모델링을 통해 나온 값을 평균하거나 다중 투표하는 방식으로 예측 모형의 분산을 줄여 줌으로써 예측력을 향상 시키는 방법입니다.\n",
        "\n",
        "일반적으로 과대적합된 모형, 분산이 큰 모형에 사용하는 것이 적합합니다.\n",
        "\n",
        "RandomForest 같은 모델입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Pjps37-o7h",
        "colab_type": "text"
      },
      "source": [
        "<H3>Gradient Boosting (앙상블 방법) - 회귀(Regression) 분석 or 분류 (Classificaiton)  \n",
        "\n",
        "테이블 형태의 데이터에 대해서 엄청난 성능을 나타낸다.\n",
        "\n",
        "LightGBM, CatBoost, XGBoost(extreme gradient boosting)이 Gradient Boosting 모델이다.\n",
        "</H3>\n",
        "\n",
        "\n",
        "<center>< 테이블 형태의 데이터>\n",
        "\n",
        "![alt text](https://d13ot9o61jdzpp.cloudfront.net/images/tabular_data_1_the_perfect_format.png) </center>\n",
        "\n",
        "부스팅 모델은 잘못 분류된 개체들에 집중하여 새로운 분류 규칙을 만드는 단계를 반복하는 방법입니다. 즉, 처음 데이터의 객체들은 동일한 가중치에서 시장하지만, 모델링을 통해 오분류된 개체들에게는 높은 가중치를 부여하고, 정분류된 객체들에게 낮은 가중치를 부여하여 오분류된 객체들이 더 잘 분류되도록 만드는 방법입니다.\n",
        "\n",
        "![alt text](https://i.imgur.com/MvCGENh.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWwRSIyP-8e0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "38bb4c9d-75c3-4d39-8bcb-5214db73c3f5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = pd.read_csv('train.csv', index_col='Id')\n",
        "x_test_full = pd.read_csv('test.csv', index_col='Id')\n",
        "\n",
        "\n",
        "# X.dropna(axis=0, subset=['SalePrice'], inplace=True) # SalePrice에 결측치가 있는 row만 삭제함\n",
        "# y = \n",
        "# X.drop(['SalePrice'], axis=1, inplace=True)\n",
        "# X_train_full, X_valid_full, y_train, y_valid = \n",
        "     \n",
        "\n",
        "#  (위 코드를 작성하세요. )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# \n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX.dropna(axis=0, subset=['SalePrice'], inplace=True) # SalePrice에 결측치가 있는 row만 삭제함\\ny = X.SalePrice\\nX.drop(['SalePrice'], axis=1, inplace=True)\\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgPvpEsaj1WK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리 개수가 적은 columns만 뽑아보기\n",
        "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype == \"object\"]\n",
        "# 수치형 데이터 뽑기\n",
        "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "my_cols = low_cardinality_cols + numeric_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()\n",
        "X_test = x_test_full[my_cols].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPqBGD5umCS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Categorical_to_nummeric(X_train, X_valid, X_test):\n",
        "#  X_train = \n",
        "#  X_valid = \n",
        "#  X_test = \n",
        "\n",
        "# X_train, X_valid = \n",
        "# X_train, X_test = \n",
        "\n",
        "#  return X_train, X_valid, X_test\n",
        "\n",
        "#  (위 코드를 작성하세요. )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ZjoxZ6mKy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def XGBboost_train(X_train, y_train, X_valid, y_valid):\n",
        "  # from xgboost import XGBRegressor\n",
        "  # model= XGBRegressor(n_estimator=1000, learning_rate=0.05, n_jobs=-1, random_state=0)\n",
        "  # model.fit(X_train, y_train,\n",
        "              # eval_set=[(X_valid, y_valid)],\n",
        "              # early_stopping_rounds=5,\n",
        "              # verbose=False)\n",
        "  # return model\n",
        "\n",
        "\n",
        "#  (위 코드를 작성하세요. )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjD6ESy4Omaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def predict_evaluate(model, X_test, y_test):\n",
        "  # from sklearn.metrics import mean_absolute_error\n",
        "  # prediction = \n",
        "  # mae = \n",
        "  # return mae\n",
        "\n",
        "#  (위 코드를 작성하세요. )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3svgkDGLKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8863ac70-26c4-4969-f43c-bf3d5a5b3df3"
      },
      "source": [
        "X_train, X_valid, X_test = Categorical_to_nummeric(X_train, X_valid, X_test) # 카테고리 데이터를 숫자형으로 인덱싱합니다. (One-Hot Encoding 방법)\n",
        "\n",
        "XGBboost_model = XGBboost_train(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "print(\"\\n\\n============== XGBboost model predict score============\")\n",
        "predict_evaluate(XGBboost_model, X_valid, y_valid)\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[06:26:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "\n",
            "============== XGBboost model predict score============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17748.012655179795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Y5LTCQN8zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "4cc4d26b-3621-43f4-b311-4ddf797745ef"
      },
      "source": [
        "# Code you have previously used to load data\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "home_data = pd.read_csv(\"new_train.csv\")\n",
        "y = home_data.SalePrice\n",
        "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
        "X = home_data[features]\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "\n",
        "#랜덤 포레스트 모델 학습\n",
        "rf_model = RandomForestRegressor(random_state=0)\n",
        "model_rf = rf_model.fit(train_X, train_y)\n",
        "prediction_rf = model_rf.predict(val_X)\n",
        "mae_rf = mean_absolute_error(prediction_rf, val_y)\n",
        "\n",
        "\n",
        "\n",
        "#XGB Boost 모델 학습\n",
        "model_xgb= XGBRegressor(n_estimator=1000, learning_rate=0.05, n_jobs=-1, random_state=0)\n",
        "model_xgb.fit(train_X, train_y,\n",
        "            eval_set=[(val_X, val_y)],\n",
        "            early_stopping_rounds=5,\n",
        "            verbose=False)\n",
        "prediction_xgb = model_xgb.predict(val_X)\n",
        "mae_XGB = mean_absolute_error(prediction_xgb, val_y)\n",
        "\n",
        "#Light GBM 모델 학습\n",
        "\n",
        "params = {'learning_rate': 0.01, \n",
        "          'max_depth': 16, \n",
        "          'boosting': 'gbdt', \n",
        "          'objective': 'regression', \n",
        "          'metric': 'auc',\n",
        "          'is_training_metric': True,\n",
        "          'num_leaves': 144,\n",
        "          'feature_fraction': 0.9,\n",
        "          'bagging_fraction': 0.7,\n",
        "          'bagging_freq': 5,\n",
        "          'seed':0}\n",
        "train_ds = lgb.Dataset(train_X, label = train_y)\n",
        "val_ds = lgb.Dataset(val_X, label = val_y)\n",
        "model_GBM = lgb.train(params,train_ds, 1000, verbose_eval=10)\n",
        "prediction_light_GBM = model_GBM.predict(val_X)\n",
        "mae_GBM = mean_absolute_error(prediction_light_GBM, val_y)\n",
        "\n",
        "print(\"\\n\\n============== Random Forest Model predict score============\")\n",
        "print(\"Validation MAE for Random Forest Model: {}\\n\\n\".format(mae_rf))\n",
        "\n",
        "print(\"\\n\\n============== XGBboost model predict score============\")\n",
        "print(\"Validation MAE for XGBboost Model: {}\\n\\n\".format(mae_XGB))\n",
        "\n",
        "print(\"\\n\\n============== LightGBM model predict score============\")\n",
        "print(\"Validation MAE for LightGBM model: {}\\n\\n\".format(mae_GBM))\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[06:46:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "\n",
            "============== Random Forest Model predict score============\n",
            "Validation MAE for Random Forest Model: 25474.17279843444\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============== XGBboost model predict score============\n",
            "Validation MAE for XGBboost Model: 24023.17861729452\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============== LightGBM model predict score============\n",
            "Validation MAE for LightGBM model: 23528.651089825627\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj-qjfCFXMwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIoQzodVsMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}